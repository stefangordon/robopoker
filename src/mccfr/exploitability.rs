//! Exploitability evaluation using Monte Carlo best response sampling.
//!
//! Measures how much a strategy can be exploited by computing the Nash gap:
//! the difference between best response and strategy values. Uses statistical
//! stopping with confidence intervals for efficient evaluation.

use crate::{
    cards::street::Street,
    mccfr::{
        nlhe::{edge::Edge, encoder::Encoder, game::Game, info::Info, solver::NLHE, turn::Turn},
        structs::tree::Tree,
        traits::{
            blueprint::Blueprint, encoder::Encoder as EncoderTrait, game::Game as GameTrait,
            profile::Profile,
        },
    },
    save::disk::Disk,
};

use petgraph::graph::NodeIndex;
use rand::{rngs::SmallRng, SeedableRng, Rng};
use rayon::prelude::*;
use std::time::{Duration, Instant};
use std::sync::atomic::{AtomicUsize, Ordering};

/// Evaluation configuration
const BATCH_SIZE: usize = 16;
const MAX_DEPTH: usize = 10;
const TARGET_CI_WIDTH: f64 = 5.0; // ±5 mbb/hand
const MIN_SAMPLES: u64 = 100;
const PROGRESS_DELAY_MS: u64 = 100;
const MC_SAMPLES: usize = 8;
const MAX_HERO_BRANCHES: usize = 6; // evaluate at most this many actions per hero decision

/// Runs exploitability evaluation with statistical stopping.
pub async fn evaluate() {
    let solver = load_solver().await;
    let mut stats = WelfordStats::new();
    let start_time = Instant::now();

    log::info!("Starting exploitability evaluation");
    log::info!("Target confidence interval: ±{TARGET_CI_WIDTH} mbb/hand");
    log::info!("Batch size: {} hands", BATCH_SIZE);

    // Create custom progress bar with message support
    let pb = {
        use indicatif::{ProgressBar, ProgressStyle};
        let pb = ProgressBar::new(100);
        let style = ProgressStyle::with_template(
            "{spinner:.cyan} [{pos:>3}/{len:3}] {elapsed:>4} | {msg}"
        ).unwrap();
        pb.set_style(style);
        pb.enable_steady_tick(Duration::from_millis(200));
        pb
    };

    loop {
        let batch_num = stats.count() / BATCH_SIZE as u64 + 1;
        let batch_start = Instant::now();

        let batch_results = evaluate_batch(&solver).await;
        let batch_duration = batch_start.elapsed();

        batch_results
            .iter()
            .for_each(|&result| stats.update(result));
        let samples = stats.count();

        let (mean, ci_width) = stats.confidence_interval();
        let elapsed = start_time.elapsed();

        // Calculate progress percentage
        let (progress_pct, stage) = if samples >= MIN_SAMPLES {
            let pct = (TARGET_CI_WIDTH / ci_width).min(1.0) * 100.0;
            (pct, "CI")
        } else {
            let pct = (samples as f64 / MIN_SAMPLES as f64) * 100.0;
            (pct, "Warmup")
        };

        pb.set_length(100);
        pb.set_position(progress_pct.round() as u64);
                pb.set_message(format!(
            "Batch {} | {:.2} ± {:.2} mbb/h | {:.1}s batch | {} stage",
            batch_num, mean, ci_width, batch_duration.as_secs_f64(), stage
        ));

        if samples >= MIN_SAMPLES && ci_width <= TARGET_CI_WIDTH {
            pb.finish_with_message(format!("✓ Converged: {:.2} mbb/h after {:.1}s", mean, elapsed.as_secs_f64()));
            break;
        }

        tokio::time::sleep(Duration::from_millis(PROGRESS_DELAY_MS)).await;
    }
}

async fn load_solver() -> NLHE {
    log::info!("Loading trained solver...");
    // Evaluation always begins at the pre-flop root, so we must load the
    // blueprint/encoder that was trained for that street.  Loading a random
    // street (flop/turn/river) causes the infoset keys to mismatch and the
    // strategy degenerates to uniform weights.  See issue #eval-street-mismatch.
    NLHE::load(Street::Pref)
}

async fn evaluate_batch(solver: &NLHE) -> Vec<f64> {
    (0..BATCH_SIZE)
        .into_par_iter()
        .map(|_i| {
            let mut rng = SmallRng::from_entropy();
            let game = Game::root();
            compute_exploitability(&game, solver.profile(), solver.encoder(), &mut rng)
        })
        .collect()
}

/// Computes exploitability for a single game using Monte Carlo rollouts.
fn compute_exploitability(
    game: &Game,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    rng: &mut SmallRng,
) -> f64 {
    // Utility helper: create a clone of `game` where the opponents' hole cards are hidden
    fn mask_game_for(game: &Game, player: usize) -> Game {
        use crate::cards::hole::Hole;

        // Start from a clone so that original `game` is untouched.
        let mut masked = game.clone();

        // Build a fresh deck excluding all currently **known** public cards and hero pocket.
        // We will draw replacement cards for every other seat so that their pocket remains size-2
        // but becomes *independent* of the hero's knowledge.
        let mut deck = masked.deck();

        let n = masked.n();
        for pos in 0..n {
            if pos != player {
                // Draw two random, distinct cards that are still available.
                let c1 = deck.draw();
                let c2 = deck.draw();
                let hole = Hole::from((c1, c2));
                masked = masked.reset_cards_at(pos, hole);
            }
        }

        // ---------------------------------------------------------
        // TODO REMOVE – Debug safety-net: verify the masking worked
        // ---------------------------------------------------------
        for pos in 0..n {
            if pos != player {
                let orig = game.hole_cards(pos);
                let new  = masked.hole_cards(pos);
                assert!(orig != new, "mask_game_for failed – opponent{} cards unchanged", pos);
            }
        }

        masked
    }

    // Check if we should trace this hand
    static TRACE_COUNT: AtomicUsize = AtomicUsize::new(0);
    let should_trace = std::env::var("TRACE_EXPLOITABILITY").is_ok()
        && TRACE_COUNT.fetch_add(1, Ordering::Relaxed) < 1;

    // Best-response values – each computed on its own copy that hides the opponent's private cards
    let br_values = [0, 1].map(|p| {
        let privless = mask_game_for(game, p);
        let mut tree = Tree::default();

        if should_trace {
            println!("\n=== COMPUTING BEST RESPONSE FOR PLAYER {} ===", p);
            println!("Masked game state: {}", privless);
            println!("Player {} sees their cards: {}", p, privless.hole_cards(p));
            for opp in 0..privless.n() {
                if opp != p {
                    println!("Opponent {} has random cards: {}", opp, privless.hole_cards(opp));
                }
            }
        }

        let value = best_response_value(&privless, profile, encoder, &mut tree, p, MAX_DEPTH, rng, should_trace);

        if should_trace {
            println!("Final BR value for player {}: {:.2} chips ({:.2} mbb/h)",
                p, value, value * 1000.0 / crate::B_BLIND as f64);
        }

        value
    });

    // Strategy values – full information not required to be masked (average strategy evaluation)
    let strategy_values = [0, 1].map(|p| {
        let mut tree = Tree::default();

        if should_trace {
            println!("\n=== COMPUTING STRATEGY VALUE FOR PLAYER {} ===", p);
        }

        let value = strategy_value(game, profile, encoder, &mut tree, p, MAX_DEPTH, rng, should_trace);

        if should_trace {
            println!("Final strategy value for player {}: {:.2} chips ({:.2} mbb/h)",
                p, value, value * 1000.0 / crate::B_BLIND as f64);
        }

        value
    });

    let exploitability = br_values
        .iter()
        .zip(&strategy_values)
        .map(|(br, strat)| br - strat)
        .sum::<f64>()
        / 2.0;

    // ---------------------------------------------------------
    // TODO REMOVE – Sanity bound: EV can never exceed total chips
    // ---------------------------------------------------------
    const MAX_POT_CHIPS: f64 = crate::STACK as f64 + crate::STACK as f64 + crate::B_BLIND as f64 + crate::S_BLIND as f64;
    let max_mbb_per_hand = MAX_POT_CHIPS * 1000.0 / crate::B_BLIND as f64;
    if exploitability.abs() > max_mbb_per_hand {
        panic!(
            "exploitability out of bounds: {:.2} mbb/h (limit {:.2}) – indicates NaNs/infinite values",
            exploitability, max_mbb_per_hand
        );
    }

    if should_trace {
        println!("\n=== EXPLOITABILITY SUMMARY ===");
        println!("Game state: {}", game);
        println!("Board: {}", game.board());
        for pos in 0..game.n() {
            println!("Player {} hole cards: {}", pos, game.hole_cards(pos));
        }
        println!("\nBest Response values: P0={:.2}, P1={:.2}", br_values[0], br_values[1]);
        println!("Strategy values: P0={:.2}, P1={:.2}", strategy_values[0], strategy_values[1]);
        println!("Nash gaps: P0={:.2}, P1={:.2}",
            br_values[0] - strategy_values[0],
            br_values[1] - strategy_values[1]);
        println!("Exploitability: {:.2} chips ({:.2} mbb/h)",
            exploitability, exploitability * 1000.0 / crate::B_BLIND as f64);
        println!("==============================\n");
    }

    // Convert chips/hand to milli-big-blinds per hand
    exploitability * 1000.0 / crate::B_BLIND as f64
}

/// Computes best response value using perfect play for the target player.
fn best_response_value(
    game: &Game,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    tree: &mut Tree<Turn, Edge, Game, Info>,
    player: usize,
    depth: usize,
    rng: &mut SmallRng,
    trace: bool,
) -> f64 {
    // Seed root node
    let root_info = encoder.seed(game);
    let root_node = tree.seed(root_info, game.clone());
    best_response_node_value(
        root_node.index(),
        profile,
        encoder,
        tree,
        player,
        depth,
        1.0,
        rng,
        trace,
        0, // initial tree depth for indentation
    )
}

/// Recursive helper that traverses the tree using encoder.info()
fn best_response_node_value(
    node_idx: NodeIndex,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    tree: &mut Tree<Turn, Edge, Game, Info>,
    player: usize,
    depth: usize,
    reach: f64,
    rng: &mut SmallRng,
    trace: bool,
    tree_depth: usize,
) -> f64 {
    let node = tree.at(node_idx);
    let game = node.game();
    let indent = "  ".repeat(tree_depth);

    if trace && tree_depth < 4 {  // Limit trace depth
        println!("{}BR[P{}] at depth {} | Turn: {:?} | Street: {:?} | Pot: {} | Reach: {:.4}",
            indent, player, tree_depth, game.turn(), game.street(), game.pot(), reach);
    }

    if depth == 0 {
        // At cut-off we roll out both players' *average* strategy until terminal
        // using Monte-Carlo sampling. This captures future-street play instead of
        // using a simple equity proxy.
        let value = reach * rollout_value(game, profile, encoder, player, rng);
        if trace && tree_depth < 4 {
            println!("{}  -> Rollout value: {:.2}", indent, value);
        }
        return value;
    }

    // Generate branches (legal edges) from this node
    let branches = encoder.branches(&node);
    if branches.is_empty() {
        let payoff = game.payoff(Turn::Choice(player)) as f64;
        let value = reach * payoff;
        if trace && tree_depth < 4 {
            println!("{}  -> Terminal payoff: {:.2} * {:.4} = {:.2}", indent, payoff, reach, value);
        }
        return value;
    }

    match game.turn() {
        Turn::Chance => {
            // Sample ONE outcome uniformly – unbiased estimate of expectation.
            let idx = rng.gen_range(0..branches.len());
            let (edge, next_game, _) = &branches[idx];

            if trace && tree_depth < 4 {
                println!("{}  -> Chance: sampled {:?} (1/{} outcomes)", indent, edge, branches.len());
            }

            let child_info = encoder.info(tree, (edge.clone(), next_game.clone(), node_idx));
            let child_node = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx));

            best_response_node_value(
                child_node.index(),
                profile,
                encoder,
                tree,
                player,
                depth - 1,
                reach, // reach unchanged – sampling implicit
                rng,
                trace,
                tree_depth + 1,
            )
        }

        Turn::Choice(p) if p == player => {
            // Player chooses the action that maximises expected value *before* seeing
            // the opponent's private cards.  For each candidate edge we Monte-Carlo
            // sample the unknown pockets of the other player(s) and average.

            if trace && tree_depth < 4 {
                println!("{}  -> Hero decision ({} actions):", indent, branches.len().min(MAX_HERO_BRANCHES));
            }

            let mut best_action = None;
            let mut best_value = f64::NEG_INFINITY;

            for (_i, (edge, next_game, _)) in branches.iter().take(MAX_HERO_BRANCHES).enumerate() {
                let mut total = 0.0;
                let mut mc_values = Vec::new(); // Track individual MC sample values

                for _mc_idx in 0..MC_SAMPLES {
                    // Resample opponents' pockets for this rollout
                    let sampled_game = {
                        // Draw new cards for all non-hero seats *after* the action is applied
                        use crate::cards::hole::Hole;
                        let mut g = next_game.clone();
                        let mut deck = g.deck();
                        for pos in 0..g.n() {
                            if pos != player {
                                let c1 = deck.draw();
                                let c2 = deck.draw();
                                g = g.reset_cards_at(pos, Hole::from((c1, c2)));
                            }
                        }
                        g
                    };

                    // Evaluate continuation value with a fresh tree to avoid interference
                    let mut sub_tree = Tree::default();
                    let v = best_response_value(
                        &sampled_game,
                        profile,
                        encoder,
                        &mut sub_tree,
                        player,
                        depth - 1,
                        rng,
                        false, // Don't trace inside MC samples
                    );
                    total += v;
                    mc_values.push(v);

                    // Check for anomalous values
                    if trace && v.abs() > 400.0 && tree_depth < 2 {
                        println!("{}    WARNING: Large MC sample value: {:.2} for {:?}", indent, v, edge);
                        println!("{}      Sampled game state: {}", indent, sampled_game);
                        println!("{}      Hero cards: {}, Opp cards: {}",
                            indent,
                            sampled_game.hole_cards(player),
                            sampled_game.hole_cards(1 - player)
                        );
                    }
                }
                let avg_value = total / MC_SAMPLES as f64;

                if trace && tree_depth < 4 {
                    // Show variance in MC samples if significant
                    let variance = if mc_values.len() > 1 {
                        let mean = avg_value;
                        mc_values.iter()
                            .map(|&x| (x - mean).powi(2))
                            .sum::<f64>() / (mc_values.len() - 1) as f64
                    } else {
                        0.0
                    };
                    let std_dev = variance.sqrt();

                    println!("{}    {:?} -> EV: {:.2} (σ={:.2}, samples={:?})",
                        indent, edge, avg_value, std_dev,
                        if std_dev > 50.0 { format!("{:?}", mc_values) } else { "...".to_string() }
                    );
                }

                if avg_value > best_value {
                    best_value = avg_value;
                    best_action = Some(edge.clone());
                }
            }

            if trace && tree_depth < 4 {
                println!("{}    => Best: {:?} with EV {:.2}", indent, best_action.unwrap(), best_value);
            }

            best_value
        }

        Turn::Choice(_) => {
            // Opponent action: sample according to their mixed strategy.
            let probs = normalize_probabilities(&branches, profile, node.info());

            if trace && tree_depth < 4 {
                println!("{}  -> Opponent decision:", indent);
                for ((edge, _, _), p) in branches.iter().zip(&probs) {
                    println!("{}    {:?} -> {:.4}", indent, edge, p);
                }
            }

            let roll = rng.gen::<f64>();
            let mut idx = 0;
            let mut cumulative = 0.0;
            for (i, p) in probs.iter().enumerate() {
                cumulative += p;
                if roll < cumulative {
                    idx = i;
                    break;
                }
            }

            let (edge, next_game, _) = &branches[idx];

            if trace && tree_depth < 4 {
                println!("{}    => Sampled: {:?}", indent, edge);
            }

            let child_info = encoder.info(tree, (edge.clone(), next_game.clone(), node_idx));
            let child_node = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx));

            best_response_node_value(
                child_node.index(),
                profile,
                encoder,
                tree,
                player,
                depth - 1,
                reach, // probability already accounted by sampling
                rng,
                trace,
                tree_depth + 1,
            )
        }

        Turn::Terminal => {
            let payoff = game.payoff(Turn::Choice(player)) as f64;
            let value = reach * payoff;
            if trace && tree_depth < 4 {
                println!("{}  -> Terminal: {:.2} * {:.4} = {:.2}", indent, payoff, reach, value);
            }
            value
        }
    }
}

/// Computes strategy value using the current profile for both players.
fn strategy_value(
    game: &Game,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    tree: &mut Tree<Turn, Edge, Game, Info>,
    player: usize,
    depth: usize,
    rng: &mut SmallRng,
    trace: bool,
) -> f64 {
    let root_info = encoder.seed(game);
    let root_node = tree.seed(root_info, game.clone());
    strategy_node_value(
        root_node.index(),
        profile,
        encoder,
        tree,
        player,
        depth,
        1.0,
        rng,
        trace,
        0, // initial tree depth
    )
}

/// Recursive helper for average-strategy rollout
fn strategy_node_value(
    node_idx: NodeIndex,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    tree: &mut Tree<Turn, Edge, Game, Info>,
    player: usize,
    depth: usize,
    reach: f64,
    rng: &mut SmallRng,
    trace: bool,
    tree_depth: usize,
) -> f64 {
    let node = tree.at(node_idx);
    let game = node.game();
    let indent = "  ".repeat(tree_depth);

    if trace && tree_depth < 4 {
        println!("{}STRAT[P{}] at depth {} | Turn: {:?} | Street: {:?} | Pot: {} | Reach: {:.4}",
            indent, player, tree_depth, game.turn(), game.street(), game.pot(), reach);
    }

    if depth == 0 {
        let value = reach * rollout_value(game, profile, encoder, player, rng);
        if trace && tree_depth < 4 {
            println!("{}  -> Rollout value: {:.2}", indent, value);
        }
        return value;
    }

    let branches = encoder.branches(&node);
    if branches.is_empty() {
        let payoff = game.payoff(Turn::Choice(player)) as f64;
        let value = reach * payoff;
        if trace && tree_depth < 4 {
            println!("{}  -> Terminal payoff: {:.2} * {:.4} = {:.2}", indent, payoff, reach, value);
        }
        return value;
    }

    match game.turn() {
        Turn::Chance => {
            let idx = rng.gen_range(0..branches.len());
            let (edge, next_game, _) = &branches[idx];

            if trace && tree_depth < 4 {
                println!("{}  -> Chance: sampled {:?} (1/{} outcomes)", indent, edge, branches.len());
            }

            let child_info = encoder.info(tree, (edge.clone(), next_game.clone(), node_idx));
            let child_node = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx));

            strategy_node_value(
                child_node.index(),
                profile,
                encoder,
                tree,
                player,
                depth - 1,
                reach,
                rng,
                trace,
                tree_depth + 1,
            )
        }

        Turn::Choice(_) => {
            let probs = normalize_probabilities(&branches, profile, node.info());

            if trace && tree_depth < 4 {
                let actor = match game.turn() {
                    Turn::Choice(p) => format!("P{}", p),
                    _ => "?".to_string(),
                };
                println!("{}  -> {} decision:", indent, actor);
                for ((edge, _, _), p) in branches.iter().zip(&probs) {
                    println!("{}    {:?} -> {:.4}", indent, edge, p);
                }
            }

            let roll = rng.gen::<f64>();
            let mut idx = 0;
            let mut cumulative = 0.0;
            for (i, p) in probs.iter().enumerate() {
                cumulative += p;
                if roll < cumulative {
                    idx = i;
                    break;
                }
            }

            let (edge, next_game, _) = &branches[idx];

            if trace && tree_depth < 4 {
                println!("{}    => Sampled: {:?}", indent, edge);
            }

            let child_info = encoder.info(tree, (edge.clone(), next_game.clone(), node_idx));
            let child_node = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx));

            strategy_node_value(
                child_node.index(),
                profile,
                encoder,
                tree,
                player,
                depth - 1,
                reach,
                rng,
                trace,
                tree_depth + 1,
            )
        }

        Turn::Terminal => {
            let payoff = game.payoff(Turn::Choice(player)) as f64;
            let value = reach * payoff;
            if trace && tree_depth < 4 {
                println!("{}  -> Terminal: {:.2} * {:.4} = {:.2}", indent, payoff, reach, value);
            }
            value
        }
    }
}

type TreeBranches = Vec<(Edge, Game, petgraph::graph::NodeIndex)>;

fn normalize_probabilities(
    branches: &TreeBranches,
    profile: &super::nlhe::profile::Profile,
    info: &Info,
) -> Vec<f64> {
    // Collect raw (potentially unnormalised) weights from the profile.
    // Clamp any negative values to zero to avoid invalid probability mass
    // which would otherwise distort the sampling and value estimates.
    let mut weights: Vec<f64> = branches
        .iter()
        .map(|(edge, _, _)| profile.advice(info, edge).max(0.0_f32) as f64)
        .collect();

    // Fallback to uniform distribution when the strategy is completely
    // uninitialised (all weights == 0).
    let sum: f64 = weights.iter().sum();
    if sum > 0.0 {
        weights.iter_mut().for_each(|w| *w /= sum);
    } else {
        let uniform = 1.0 / weights.len() as f64;
        weights.iter_mut().for_each(|w| *w = uniform);
    }

    // Additional validation for extreme values
    let has_extreme = weights.iter().any(|&p| p > 0.99 || (p > 0.0 && p < 0.01));
    if has_extreme && std::env::var("TRACE_EXPLOITABILITY").is_ok() {
        static EXTREME_COUNT: AtomicUsize = AtomicUsize::new(0);
        if EXTREME_COUNT.fetch_add(1, Ordering::Relaxed) < 5 {
            println!("WARNING: Extreme probability distribution detected:");
            for ((edge, _, _), p) in branches.iter().zip(&weights) {
                if *p > 0.99 || (*p > 0.0 && *p < 0.01) {
                    println!("  {:?} -> {:.6}", edge, p);
                }
            }
        }
    }

    debug_assert!(weights.iter().all(|&p| p.is_finite() && p >= 0.0), "Invalid probability vector");
    debug_assert!((weights.iter().sum::<f64>() - 1.0).abs() < 1e-9, "Probabilities do not sum to 1 (got {})", weights.iter().sum::<f64>());

    weights
}

/// Roll-out from the current state to the end of the hand by *sampling*
/// actions and chance events with both players following their average
/// strategy. Returns chip EV for `player` from this state.
fn rollout_value(
    game: &Game,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    player: usize,
    rng: &mut SmallRng,
) -> f64 {
    // Track anomalous rollouts
    static ROLLOUT_TRACE_COUNT: AtomicUsize = AtomicUsize::new(0);
    let _trace_rollout = std::env::var("TRACE_ROLLOUT").is_ok()
        && ROLLOUT_TRACE_COUNT.load(Ordering::Relaxed) < 5;

    // We reuse a tiny scratch tree only to let the encoder generate branches.
    let mut tree: Tree<Turn, Edge, Game, Info> = Tree::default();
    let mut node_idx = {
        let info = encoder.seed(game);
        tree.seed(info, game.clone()).index()
    };

    let initial_pot = game.pot();
    let mut step_count = 0;

    loop {
        let node = tree.at(node_idx);
        let g = node.game();
        step_count += 1;

        match g.turn() {
            Turn::Terminal => {
                let payoff = g.payoff(Turn::Choice(player)) as f64;

                // Check for anomalous payoffs
                if payoff.abs() > 300.0 && ROLLOUT_TRACE_COUNT.fetch_add(1, Ordering::Relaxed) < 5 {
                    println!("\n=== ANOMALOUS ROLLOUT DETECTED ===");
                    println!("Initial pot: {}, Final pot: {}", initial_pot, g.pot());
                    println!("Player {} payoff: {:.2} chips", player, payoff);
                    println!("Steps taken: {}", step_count);
                    println!("Final game state: {}", g);
                    println!("Board: {}", g.board());
                    for p in 0..g.n() {
                        println!("Player {} cards: {}", p, g.hole_cards(p));
                    }
                    println!("================================\n");
                }

                return payoff;
            }

            Turn::Chance => {
                let branches = encoder.branches(&node);
                let idx = rng.gen_range(0..branches.len());
                let (edge, next_game, _) = &branches[idx];
                let child_info = encoder.info(&tree, (edge.clone(), next_game.clone(), node_idx));
                node_idx = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx)).index();
            }

            Turn::Choice(_) => {
                let branches = encoder.branches(&node);
                let probs = normalize_probabilities(&branches, profile, node.info());
                let roll = rng.gen::<f64>();
                let mut cumulative = 0.0;
                let mut selected = 0;
                for (i, p) in probs.iter().enumerate() {
                    cumulative += p;
                    if roll < cumulative {
                        selected = i;
                        break;
                    }
                }
                let (edge, next_game, _) = &branches[selected];
                let child_info = encoder.info(&tree, (edge.clone(), next_game.clone(), node_idx));
                node_idx = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx)).index();
            }
        }

        // Safety check for infinite loops
        if step_count > 100 {
            println!("WARNING: Rollout exceeded 100 steps, aborting");
            return 0.0;
        }
    }
}

/// Welford's online algorithm for computing running statistics.
#[derive(Debug, Clone)]
struct WelfordStats {
    count: u64,
    mean: f64,
    m2: f64, // Sum of squared deviations
}

impl WelfordStats {
    const fn new() -> Self {
        Self {
            count: 0,
            mean: 0.0,
            m2: 0.0,
        }
    }

    fn update(&mut self, value: f64) {
        self.count += 1;
        let delta = value - self.mean;
        self.mean += delta / self.count as f64;
        self.m2 += delta * (value - self.mean);
    }

    const fn count(&self) -> u64 {
        self.count
    }

    fn std_error(&self) -> f64 {
        if self.count < 2 {
            return f64::INFINITY;
        }
        let variance = self.m2 / (self.count - 1) as f64;
        (variance / self.count as f64).sqrt()
    }

    /// Returns (mean, 95% CI width).
    fn confidence_interval(&self) -> (f64, f64) {
        (self.mean, 1.96 * self.std_error())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::cards::{rank::Rank, ranking::Ranking};
    use std::cmp::Ordering;

    #[test]
    fn test_equity_logic_with_known_hands() {
        // Test a scenario where we know the outcome
        // Royal flush vs high card should be 100% equity

        // We'll create hands manually to test the core logic
        let royal_flush = Ranking::StraightFlush(Rank::Ace);
        let high_card = Ranking::HighCard(Rank::Ace);

        // Test the comparison directly
        let comparison = royal_flush.cmp(&high_card);

        match comparison {
            Ordering::Greater => {
                println!("✓ CORRECT: Royal flush > high card (Greater)");
                assert!(true);
            }
            Ordering::Less => {
                println!("❌ BUG: Royal flush < high card (Less) - COMPARISON IS BACKWARDS!");
                panic!("Ranking comparison is backwards! Royal flush should beat high card");
            }
            Ordering::Equal => {
                println!("❌ BUG: Royal flush = high card (Equal) - This shouldn't happen");
                panic!("Ranking comparison failed - royal flush equals high card");
            }
        }

        // Test the actual function that would be called
        let hero_wins_result = match royal_flush.cmp(&high_card) {
            Ordering::Greater => 1.0, // Hero wins
            Ordering::Equal => 0.5,   // Tie
            Ordering::Less => 0.0,    // Hero loses
        };

        assert_eq!(
            hero_wins_result, 1.0,
            "Royal flush should beat high card (equity = 1.0)"
        );
        println!("✓ Equity calculation logic is correct");
    }

    // WelfordStats tests
    #[test]
    fn test_welford_stats_new() {
        let stats = WelfordStats::new();
        assert_eq!(stats.count(), 0);
        assert_eq!(stats.mean, 0.0);
        assert_eq!(stats.m2, 0.0);
    }

    #[test]
    fn test_welford_stats_single_value() {
        let mut stats = WelfordStats::new();
        stats.update(5.0);

        assert_eq!(stats.count(), 1);
        let (mean, ci_width) = stats.confidence_interval();
        assert_eq!(mean, 5.0);
        // With only one sample, confidence interval should be infinite
        assert!(ci_width.is_infinite());
    }

    #[test]
    fn test_welford_stats_two_values() {
        let mut stats = WelfordStats::new();
        stats.update(1.0);
        stats.update(3.0);

        assert_eq!(stats.count(), 2);
        let (mean, ci_width) = stats.confidence_interval();
        assert_eq!(mean, 2.0); // Mean of [1, 3] is 2

        // Standard error = std_dev / sqrt(n) = sqrt(2) / sqrt(2) = 1.0
        let expected_ci_width = 1.96 * 1.0; // 95% CI
        assert!((ci_width - expected_ci_width).abs() < 1e-10);
    }

    #[test]
    fn test_welford_stats_known_sequence() {
        let mut stats = WelfordStats::new();
        let values = [1.0, 2.0, 3.0, 4.0, 5.0];

        for &val in &values {
            stats.update(val);
        }

        assert_eq!(stats.count(), 5);
        let (mean, _) = stats.confidence_interval();
        assert!((mean - 3.0).abs() < 1e-10); // Mean should be 3.0

        // Variance of [1,2,3,4,5] is 2.5, std_dev = sqrt(2.5) ≈ 1.5811
        // Standard error = 1.5811 / sqrt(5) ≈ 0.7071
        let std_error = stats.std_error();
        let expected_std_error = (2.5_f64).sqrt() / (5.0_f64).sqrt();
        assert!((std_error - expected_std_error).abs() < 1e-10);
    }

    #[test]
    fn test_welford_stats_identical_values() {
        let mut stats = WelfordStats::new();
        for _ in 0..10 {
            stats.update(42.0);
        }

        assert_eq!(stats.count(), 10);
        let (mean, ci_width) = stats.confidence_interval();
        assert_eq!(mean, 42.0);
        assert_eq!(ci_width, 0.0); // No variance means no confidence interval
    }

    #[test]
    fn test_welford_stats_negative_values() {
        let mut stats = WelfordStats::new();
        stats.update(-5.0);
        stats.update(-3.0);
        stats.update(-1.0);

        assert_eq!(stats.count(), 3);
        let (mean, _) = stats.confidence_interval();
        assert_eq!(mean, -3.0); // Mean of [-5, -3, -1] is -3
    }
}
