//! Exploitability evaluation using Monte Carlo best response sampling.
//!
//! Measures how much a strategy can be exploited by computing the Nash gap:
//! the difference between best response and strategy values. Uses statistical
//! stopping with confidence intervals for efficient evaluation.

use crate::{
    cards::street::Street,
    mccfr::{
        nlhe::{edge::Edge, encoder::Encoder, game::Game, info::Info, solver::NLHE, turn::Turn},
        structs::tree::Tree,
        traits::{
            blueprint::Blueprint, encoder::Encoder as EncoderTrait, game::Game as GameTrait,
            profile::Profile,
        },
    },
    save::disk::Disk,
    Arbitrary, B_BLIND,
    cards::hole::Hole,
};

use petgraph::graph::NodeIndex;
use rand::{rngs::SmallRng, SeedableRng, Rng};
use rayon::prelude::*;
use std::time::{Duration, Instant};

/// Evaluation configuration
const BATCH_SIZE: usize = 1024;
const MAX_DEPTH: usize = crate::MAX_DEPTH_SUBGAME;
const TARGET_CI_WIDTH: f64 = 5.0; // ±5 mbb/hand
const MIN_SAMPLES: u64 = 100;
const PROGRESS_DELAY_MS: u64 = 100;

/// Runs exploitability evaluation with statistical stopping.
pub async fn evaluate() {
    let solver = load_solver().await;
    let mut stats = WelfordStats::new();
    let start_time = Instant::now();

    log::info!("Starting exploitability evaluation");
    log::info!("Target confidence interval: ±{TARGET_CI_WIDTH} mbb/hand");
    log::info!("Batch size: {} hands", BATCH_SIZE);

    // Create custom progress bar with message support
    let pb = {
        use indicatif::{ProgressBar, ProgressStyle};
        let pb = ProgressBar::new(100);
        let style = ProgressStyle::with_template(
            "{spinner:.cyan} [{pos:>3}/{len:3}] {elapsed:>4} | {msg}"
        ).unwrap();
        pb.set_style(style);
        pb.enable_steady_tick(Duration::from_millis(200));
        pb
    };

    loop {
        let batch_num = stats.count() / BATCH_SIZE as u64 + 1;
        let batch_start = Instant::now();

        let batch_results = evaluate_batch(&solver).await;
        let batch_duration = batch_start.elapsed();

        batch_results
            .iter()
            .for_each(|&result| stats.update(result));
        let samples = stats.count();

        let (mean, ci_width) = stats.confidence_interval();
        let elapsed = start_time.elapsed();

        // Calculate progress percentage
        let (progress_pct, stage) = if samples >= MIN_SAMPLES {
            let pct = (TARGET_CI_WIDTH / ci_width).min(1.0) * 100.0;
            (pct, "CI")
        } else {
            let pct = (samples as f64 / MIN_SAMPLES as f64) * 100.0;
            (pct, "Warmup")
        };

        pb.set_length(100);
        pb.set_position(progress_pct.round() as u64);
                pb.set_message(format!(
            "Batch {} | {:.2} ± {:.2} mbb/h | {:.1}s batch | {} stage",
            batch_num, mean, ci_width, batch_duration.as_secs_f64(), stage
        ));

        if samples >= MIN_SAMPLES && ci_width <= TARGET_CI_WIDTH {
            pb.finish_with_message(format!("✓ Converged: {:.2} mbb/h after {:.1}s", mean, elapsed.as_secs_f64()));
            break;
        }

        tokio::time::sleep(Duration::from_millis(PROGRESS_DELAY_MS)).await;
    }
}

async fn load_solver() -> NLHE {
    log::info!("Loading trained solver...");
    NLHE::load(Street::random())
}

async fn evaluate_batch(solver: &NLHE) -> Vec<f64> {
    (0..BATCH_SIZE)
        .into_par_iter()
        .map(|_i| {
            let mut rng = SmallRng::from_entropy();
            let game = Game::root();
            compute_exploitability(&game, solver.profile(), solver.encoder(), &mut rng)
        })
        .collect()
}

/// Computes exploitability for a single game using Monte Carlo rollouts.
fn compute_exploitability(
    game: &Game,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    rng: &mut SmallRng,
) -> f64 {
    // Utility helper: create a clone of `game` where the opponents' hole cards are hidden
    fn mask_game_for(game: &Game, player: usize, rng: &mut SmallRng) -> Game {
        use crate::cards::{deck::Deck, hole::Hole};

        // Start from a clone so that original `game` is untouched.
        let mut masked = game.clone();

        // Build a fresh deck excluding all currently **known** public cards and hero pocket.
        // We will draw replacement cards for every other seat so that their pocket remains size-2
        // but becomes *independent* of the hero's knowledge.
        let mut deck = masked.deck();

        let n = masked.n();
        for pos in 0..n {
            if pos != player {
                // Draw two random, distinct cards that are still available.
                let c1 = deck.draw();
                let c2 = deck.draw();
                let hole = Hole::from((c1, c2));
                masked = masked.reset_cards_at(pos, hole);
            }
        }

        masked
    }

    // Best-response values – each computed on its own copy that hides the opponent's private cards
    let br_values = [0, 1].map(|p| {
        let privless = mask_game_for(game, p, rng);
        let mut tree = Tree::default();
        best_response_value(&privless, profile, encoder, &mut tree, p, MAX_DEPTH, rng)
    });

    // Strategy values – full information not required to be masked (average strategy evaluation)
    let strategy_values = [0, 1].map(|p| {
        let mut tree = Tree::default();
        strategy_value(game, profile, encoder, &mut tree, p, MAX_DEPTH, rng)
    });

    let exploitability = br_values
        .iter()
        .zip(&strategy_values)
        .map(|(br, strat)| br - strat)
        .sum::<f64>()
        / 2.0;

    // Convert chips/hand to milli-big-blinds per hand
    exploitability * 1000.0 / B_BLIND as f64
}

/// Computes best response value using perfect play for the target player.
fn best_response_value(
    game: &Game,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    tree: &mut Tree<Turn, Edge, Game, Info>,
    player: usize,
    depth: usize,
    rng: &mut SmallRng,
) -> f64 {
    // Seed root node
    let root_info = encoder.seed(game);
    let root_node = tree.seed(root_info, game.clone());
    best_response_node_value(
        root_node.index(),
        profile,
        encoder,
        tree,
        player,
        depth,
        1.0,
        rng,
    )
}

/// Recursive helper that traverses the tree using encoder.info()
fn best_response_node_value(
    node_idx: NodeIndex,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    tree: &mut Tree<Turn, Edge, Game, Info>,
    player: usize,
    depth: usize,
    reach: f64,
    rng: &mut SmallRng,
) -> f64 {
    let node = tree.at(node_idx);
    let game = node.game();

    if depth == 0 {
        // At cut-off we roll out both players' *average* strategy until terminal
        // using Monte-Carlo sampling. This captures future-street play instead of
        // using a simple equity proxy.
        return reach * rollout_value(game, profile, encoder, player, rng);
    }

    // Generate branches (legal edges) from this node
    let branches = encoder.branches(&node);
    if branches.is_empty() {
        return reach * game.payoff(Turn::Choice(player)) as f64;
    }

    match game.turn() {
        Turn::Chance => {
            // Sample ONE outcome uniformly – unbiased estimate of expectation.
            let idx = rng.gen_range(0..branches.len());
            let (edge, next_game, _) = &branches[idx];
            let child_info = encoder.info(tree, (edge.clone(), next_game.clone(), node_idx));
            let child_node = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx));

            best_response_node_value(
                child_node.index(),
                profile,
                encoder,
                tree,
                player,
                depth - 1,
                reach, // reach unchanged – sampling implicit
                rng,
            )
        }

        Turn::Choice(p) if p == player => {
            // Player chooses the action that maximises expected value.
            branches
                .iter()
                .map(|(edge, next_game, _)| {
                    let child_info =
                        encoder.info(tree, (edge.clone(), next_game.clone(), node_idx));
                    let child_node =
                        tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx));
                    best_response_node_value(
                        child_node.index(),
                        profile,
                        encoder,
                        tree,
                        player,
                        depth - 1,
                        reach,
                        rng,
                    )
                })
                .fold(f64::NEG_INFINITY, f64::max)
        }

        Turn::Choice(_) => {
            // Opponent action: sample according to their mixed strategy.
            let probs = normalize_probabilities(&branches, profile, node.info());
            let roll = rng.gen::<f64>();
            let mut idx = 0;
            let mut cumulative = 0.0;
            for (i, p) in probs.iter().enumerate() {
                cumulative += p;
                if roll < cumulative {
                    idx = i;
                    break;
                }
            }

            let (edge, next_game, _) = &branches[idx];
            let child_info = encoder.info(tree, (edge.clone(), next_game.clone(), node_idx));
            let child_node = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx));

            best_response_node_value(
                child_node.index(),
                profile,
                encoder,
                tree,
                player,
                depth - 1,
                reach, // probability already accounted by sampling
                rng,
            )
        }

        Turn::Terminal => reach * game.payoff(Turn::Choice(player)) as f64,
    }
}

/// Computes strategy value using the current profile for both players.
fn strategy_value(
    game: &Game,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    tree: &mut Tree<Turn, Edge, Game, Info>,
    player: usize,
    depth: usize,
    rng: &mut SmallRng,
) -> f64 {
    let root_info = encoder.seed(game);
    let root_node = tree.seed(root_info, game.clone());
    strategy_node_value(
        root_node.index(),
        profile,
        encoder,
        tree,
        player,
        depth,
        1.0,
        rng,
    )
}

/// Recursive helper for average-strategy rollout
fn strategy_node_value(
    node_idx: NodeIndex,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    tree: &mut Tree<Turn, Edge, Game, Info>,
    player: usize,
    depth: usize,
    reach: f64,
    rng: &mut SmallRng,
) -> f64 {
    let node = tree.at(node_idx);
    let game = node.game();

    if depth == 0 {
        return reach * rollout_value(game, profile, encoder, player, rng);
    }

    let branches = encoder.branches(&node);
    if branches.is_empty() {
        return reach * game.payoff(Turn::Choice(player)) as f64;
    }

    match game.turn() {
        Turn::Chance => {
            let idx = rng.gen_range(0..branches.len());
            let (edge, next_game, _) = &branches[idx];
            let child_info = encoder.info(tree, (edge.clone(), next_game.clone(), node_idx));
            let child_node = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx));

            strategy_node_value(
                child_node.index(),
                profile,
                encoder,
                tree,
                player,
                depth - 1,
                reach,
                rng,
            )
        }

        Turn::Choice(_) => {
            let probs = normalize_probabilities(&branches, profile, node.info());
            let roll = rng.gen::<f64>();
            let mut idx = 0;
            let mut cumulative = 0.0;
            for (i, p) in probs.iter().enumerate() {
                cumulative += p;
                if roll < cumulative {
                    idx = i;
                    break;
                }
            }

            let (edge, next_game, _) = &branches[idx];
            let child_info = encoder.info(tree, (edge.clone(), next_game.clone(), node_idx));
            let child_node = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx));

            strategy_node_value(
                child_node.index(),
                profile,
                encoder,
                tree,
                player,
                depth - 1,
                reach,
                rng,
            )
        }

        Turn::Terminal => reach * game.payoff(Turn::Choice(player)) as f64,
    }
}

type TreeBranches = Vec<(Edge, Game, petgraph::graph::NodeIndex)>;

fn normalize_probabilities(
    branches: &TreeBranches,
    profile: &super::nlhe::profile::Profile,
    info: &Info,
) -> Vec<f64> {
    let mut probs: Vec<f64> = branches
        .iter()
        .map(|(edge, _, _)| profile.advice(info, edge) as f64)
        .collect();

    let sum: f64 = probs.iter().sum();
    if sum > 0.0 {
        probs.iter_mut().for_each(|p| *p /= sum);
    } else {
        let len = probs.len() as f64;
        probs.fill(1.0 / len);
    }
    probs
}

/// Roll-out from the current state to the end of the hand by *sampling*
/// actions and chance events with both players following their average
/// strategy. Returns chip EV for `player` from this state.
fn rollout_value(
    game: &Game,
    profile: &super::nlhe::profile::Profile,
    encoder: &Encoder,
    player: usize,
    rng: &mut SmallRng,
) -> f64 {
    // We reuse a tiny scratch tree only to let the encoder generate branches.
    let mut tree: Tree<Turn, Edge, Game, Info> = Tree::default();
    let mut node_idx = {
        let info = encoder.seed(game);
        tree.seed(info, game.clone()).index()
    };

    loop {
        let node = tree.at(node_idx);
        let g = node.game();

        match g.turn() {
            Turn::Terminal => {
                return g.payoff(Turn::Choice(player)) as f64;
            }

            Turn::Chance => {
                let branches = encoder.branches(&node);
                let idx = rng.gen_range(0..branches.len());
                let (edge, next_game, _) = &branches[idx];
                let child_info = encoder.info(&tree, (edge.clone(), next_game.clone(), node_idx));
                node_idx = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx)).index();
            }

            Turn::Choice(_) => {
                let branches = encoder.branches(&node);
                let probs = normalize_probabilities(&branches, profile, node.info());
                let roll = rng.gen::<f64>();
                let mut cumulative = 0.0;
                let mut selected = 0;
                for (i, p) in probs.iter().enumerate() {
                    cumulative += p;
                    if roll < cumulative {
                        selected = i;
                        break;
                    }
                }
                let (edge, next_game, _) = &branches[selected];
                let child_info = encoder.info(&tree, (edge.clone(), next_game.clone(), node_idx));
                node_idx = tree.grow(child_info, (edge.clone(), next_game.clone(), node_idx)).index();
            }
        }
    }
}

/// Welford's online algorithm for computing running statistics.
#[derive(Debug, Clone)]
struct WelfordStats {
    count: u64,
    mean: f64,
    m2: f64, // Sum of squared deviations
}

impl WelfordStats {
    const fn new() -> Self {
        Self {
            count: 0,
            mean: 0.0,
            m2: 0.0,
        }
    }

    fn update(&mut self, value: f64) {
        self.count += 1;
        let delta = value - self.mean;
        self.mean += delta / self.count as f64;
        self.m2 += delta * (value - self.mean);
    }

    const fn count(&self) -> u64 {
        self.count
    }

    fn std_error(&self) -> f64 {
        if self.count < 2 {
            return f64::INFINITY;
        }
        let variance = self.m2 / (self.count - 1) as f64;
        (variance / self.count as f64).sqrt()
    }

    /// Returns (mean, 95% CI width).
    fn confidence_interval(&self) -> (f64, f64) {
        (self.mean, 1.96 * self.std_error())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::cards::{rank::Rank, ranking::Ranking};
    use std::cmp::Ordering;

    #[test]
    fn test_equity_logic_with_known_hands() {
        // Test a scenario where we know the outcome
        // Royal flush vs high card should be 100% equity

        // We'll create hands manually to test the core logic
        let royal_flush = Ranking::StraightFlush(Rank::Ace);
        let high_card = Ranking::HighCard(Rank::Ace);

        // Test the comparison directly
        let comparison = royal_flush.cmp(&high_card);

        match comparison {
            Ordering::Greater => {
                println!("✓ CORRECT: Royal flush > high card (Greater)");
                assert!(true);
            }
            Ordering::Less => {
                println!("❌ BUG: Royal flush < high card (Less) - COMPARISON IS BACKWARDS!");
                panic!("Ranking comparison is backwards! Royal flush should beat high card");
            }
            Ordering::Equal => {
                println!("❌ BUG: Royal flush = high card (Equal) - This shouldn't happen");
                panic!("Ranking comparison failed - royal flush equals high card");
            }
        }

        // Test the actual function that would be called
        let hero_wins_result = match royal_flush.cmp(&high_card) {
            Ordering::Greater => 1.0, // Hero wins
            Ordering::Equal => 0.5,   // Tie
            Ordering::Less => 0.0,    // Hero loses
        };

        assert_eq!(
            hero_wins_result, 1.0,
            "Royal flush should beat high card (equity = 1.0)"
        );
        println!("✓ Equity calculation logic is correct");
    }

    // WelfordStats tests
    #[test]
    fn test_welford_stats_new() {
        let stats = WelfordStats::new();
        assert_eq!(stats.count(), 0);
        assert_eq!(stats.mean, 0.0);
        assert_eq!(stats.m2, 0.0);
    }

    #[test]
    fn test_welford_stats_single_value() {
        let mut stats = WelfordStats::new();
        stats.update(5.0);

        assert_eq!(stats.count(), 1);
        let (mean, ci_width) = stats.confidence_interval();
        assert_eq!(mean, 5.0);
        // With only one sample, confidence interval should be infinite
        assert!(ci_width.is_infinite());
    }

    #[test]
    fn test_welford_stats_two_values() {
        let mut stats = WelfordStats::new();
        stats.update(1.0);
        stats.update(3.0);

        assert_eq!(stats.count(), 2);
        let (mean, ci_width) = stats.confidence_interval();
        assert_eq!(mean, 2.0); // Mean of [1, 3] is 2

        // Standard error = std_dev / sqrt(n) = sqrt(2) / sqrt(2) = 1.0
        let expected_ci_width = 1.96 * 1.0; // 95% CI
        assert!((ci_width - expected_ci_width).abs() < 1e-10);
    }

    #[test]
    fn test_welford_stats_known_sequence() {
        let mut stats = WelfordStats::new();
        let values = [1.0, 2.0, 3.0, 4.0, 5.0];

        for &val in &values {
            stats.update(val);
        }

        assert_eq!(stats.count(), 5);
        let (mean, _) = stats.confidence_interval();
        assert!((mean - 3.0).abs() < 1e-10); // Mean should be 3.0

        // Variance of [1,2,3,4,5] is 2.5, std_dev = sqrt(2.5) ≈ 1.5811
        // Standard error = 1.5811 / sqrt(5) ≈ 0.7071
        let std_error = stats.std_error();
        let expected_std_error = (2.5_f64).sqrt() / (5.0_f64).sqrt();
        assert!((std_error - expected_std_error).abs() < 1e-10);
    }

    #[test]
    fn test_welford_stats_identical_values() {
        let mut stats = WelfordStats::new();
        for _ in 0..10 {
            stats.update(42.0);
        }

        assert_eq!(stats.count(), 10);
        let (mean, ci_width) = stats.confidence_interval();
        assert_eq!(mean, 42.0);
        assert_eq!(ci_width, 0.0); // No variance means no confidence interval
    }

    #[test]
    fn test_welford_stats_negative_values() {
        let mut stats = WelfordStats::new();
        stats.update(-5.0);
        stats.update(-3.0);
        stats.update(-1.0);

        assert_eq!(stats.count(), 3);
        let (mean, _) = stats.confidence_interval();
        assert_eq!(mean, -3.0); // Mean of [-5, -3, -1] is -3
    }
}
